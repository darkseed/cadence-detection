{
 "metadata": {
  "name": "",
  "signature": "sha256:7dbab4620c5aa18931cf995dea0d0baae8d8e77771fdcd0c590a53dfb6de67eb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Cadence Detection in Dutch folks songs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook serves as a background to the computational experiments on cadence detection in Dutch folk songs. All scripts that are used in this notebook can be found in the same directory as this notebook. We start with importing some of the classes and functions in the cadencer.py script. Most importantly, we import the CandenceClassifier which takes as argument a classifier of choice available in the scikit-learn library. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from cadencer import CadenceClassifier, load_data, FEATURES\n",
      "from cadencer import unzip, flatten, decode\n",
      "\n",
      "%cd '/Users/pvk/rep/cadence-detection'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/pvk/rep/cadence-detection\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we use the function `load_data` to load the data with all features extracted into the namespace."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data, IDs = load_data('data/trigram_dataset_note_20150202.pkl', features='all_20140503b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following function performs $n$-fold cross-validation on the dataset. It takes as argument the data loaded with the `load_data` function as well as an instance of the `CadenceClassifier`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data[0][0][0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "59"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.metrics import precision_recall_fscore_support, f1_score, fbeta_score\n",
      "\n",
      "\n",
      "def cross_validate(data, IDs, clf, n_folds=10, shuffle=True, random_state=None, verbose=False):\n",
      "    scores = pd.DataFrame(columns=['fold', 'class', 'precision', 'recall', 'F'])\n",
      "    scoresPerSong = pd.DataFrame(columns=['ID', 'F1', 'F2'])\n",
      "    predictionsPerSong = {}\n",
      "    n_experiments = 0\n",
      "    n_songs = 0\n",
      "    for fold, (train_ixs, test_ixs) in enumerate(KFold(len(data), n_folds=n_folds, shuffle=shuffle, random_state=random_state)):\n",
      "        train, test = data[train_ixs], data[test_ixs]\n",
      "        X_train, y_train, indices_train = unzip(flatten(train))\n",
      "        y_train = np.array(y_train)\n",
      "        clf.fit(X_train, y_train)\n",
      "        all_preds = []\n",
      "        all_y_test = []\n",
      "\n",
      "        for k, i_test in enumerate(test): #for each melody\n",
      "            X_test, y_test, indices_test = unzip(i_test)\n",
      "            _, y_test, _ = unzip(map(decode, y_test))\n",
      "            preds = clf.predict(X_test)\n",
      "            all_y_test.extend(y_test)\n",
      "            all_preds.extend(preds)\n",
      "            scoresPerSong.loc[n_songs] = [IDs[test_ixs[k]], f1_score(y_test, preds, pos_label=1, average='weighted'), fbeta_score(y_test, preds, beta=2.0, pos_label=1, average='weighted')]\n",
      "            n_songs += 1\n",
      "            predictionsPerSong[IDs[test_ixs[k]]] = [0] #keep list of note indices of phrase _beginnings_\n",
      "            for tr_ix, pred in enumerate(preds[:-1]):\n",
      "                if pred == 1:\n",
      "                    predictionsPerSong[IDs[test_ixs[k]]].append(indices_test[tr_ix][5]+1)\n",
      "        p, r, f, _ = precision_recall_fscore_support(all_y_test, all_preds)\n",
      "        if verbose:\n",
      "            for klass in (0, 1):\n",
      "                print \"Fold: %s, Class: %s, Precision: %.3f, Recall: %.3f, F-score %.3f\" % (\n",
      "                    fold, klass, p[klass], r[klass], f[klass])\n",
      "        scores.loc[n_experiments] = np.array([fold, 0, p[0], r[0], f[0]])\n",
      "        scores.loc[n_experiments+1] = np.array([fold, 1, p[1], r[1], f[1]])\n",
      "        n_experiments += 2\n",
      "    return scores.astype(float), scoresPerSong, predictionsPerSong"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use a Random Forest Classifier as implemented in scikit-learn. The `CadenceClassifier` allows to specify the kind of label trigram prediction to perform. This can be `majority` or `weighted`. `majority` uses a majority voting system over the trigrams. `weighted` uses a weighted voting system based on the prediction probabilities of the label trigrams.\n",
      "\n",
      "We start with the `majority` voter. Initialize an estimator, then initialize a `CadenceClassifier` and perform 10-fold cross-validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "estimator = RandomForestClassifier(n_estimators=50, min_samples_leaf=1, n_jobs=6)\n",
      "clf = CadenceClassifier(estimator)\n",
      "majority_scores, majority_scores_persong, predictionsPerSong = cross_validate(data, IDs, clf, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold: 0, Class: 0, Precision: 0.964, Recall: 0.988, F-score 0.976\n",
        "Fold: 0, Class: 1, Precision: 0.889, Recall: 0.712, F-score 0.791\n",
        "Fold: 1, Class: 0, Precision: 0.966, Recall: 0.990, F-score 0.978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 1, Class: 1, Precision: 0.906, Recall: 0.735, F-score 0.812\n",
        "Fold: 2, Class: 0, Precision: 0.966, Recall: 0.989, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 2, Class: 1, Precision: 0.895, Recall: 0.734, F-score 0.806\n",
        "Fold: 3, Class: 0, Precision: 0.966, Recall: 0.987, F-score 0.976"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 3, Class: 1, Precision: 0.879, Recall: 0.730, F-score 0.797\n",
        "Fold: 4, Class: 0, Precision: 0.961, Recall: 0.990, F-score 0.975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 4, Class: 1, Precision: 0.903, Recall: 0.701, F-score 0.789\n",
        "Fold: 5, Class: 0, Precision: 0.965, Recall: 0.989, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 5, Class: 1, Precision: 0.891, Recall: 0.724, F-score 0.799\n",
        "Fold: 6, Class: 0, Precision: 0.966, Recall: 0.988, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 6, Class: 1, Precision: 0.883, Recall: 0.729, F-score 0.798\n",
        "Fold: 7, Class: 0, Precision: 0.962, Recall: 0.988, F-score 0.975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 7, Class: 1, Precision: 0.883, Recall: 0.708, F-score 0.786\n",
        "Fold: 8, Class: 0, Precision: 0.966, Recall: 0.988, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 8, Class: 1, Precision: 0.890, Recall: 0.732, F-score 0.803\n",
        "Fold: 9, Class: 0, Precision: 0.965, Recall: 0.990, F-score 0.978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 9, Class: 1, Precision: 0.907, Recall: 0.730, F-score 0.809\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print predictionsPerSong['NLB146398_01']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 9.0, 18.0]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "with open('predictions_per_song_20140503b-2.json', 'w') as fp:\n",
      "    json.dump(predictionsPerSong, fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_full(x):\n",
      "    pd.set_option('display.max_rows', len(x))\n",
      "    print(x)\n",
      "    pd.reset_option('display.max_rows')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Choose the 30 songs with lowest f1 value, and a radom sample of 30 songs with f1==1.0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "np.random.seed(1)\n",
      "majority_sel_bad = majority_scores_persong.sort('F1')[0:50]\n",
      "rows = np.random.choice(majority_scores_persong[majority_scores_persong['F1']==1.0].index.values, 50)\n",
      "majority_sel_good = majority_scores_persong.ix[rows]\n",
      "majority_sel = [majority_sel_bad, majority_sel_good]\n",
      "majority_sel = pd.concat(majority_sel)\n",
      "print_full(majority_sel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                ID        F1        F2\n",
        "1828  NLB148151_01  0.000000  0.000000\n",
        "3285  NLB074877_01  0.000000  0.000000\n",
        "710   NLB072879_01  0.000000  0.000000\n",
        "2549  NLB070708_01  0.000000  0.000000\n",
        "1864  NLB111758_01  0.000000  0.000000\n",
        "3967  NLB140256_01  0.000000  0.000000\n",
        "3601  NLB075331_01  0.000000  0.000000\n",
        "2631  NLB075756_01  0.000000  0.000000\n",
        "1187  NLB070465_01  0.000000  0.000000\n",
        "3737  NLB074226_02  0.000000  0.000000\n",
        "352   NLB140273_01  0.000000  0.000000\n",
        "3404  NLB071196_01  0.153846  0.116279\n",
        "2531  NLB075167_01  0.166667  0.128205\n",
        "2330  NLB140989_01  0.200000  0.135135\n",
        "2563  NLB070769_01  0.200000  0.161290\n",
        "2518  NLB075878_01  0.200000  0.147059\n",
        "2570  NLB112002_01  0.200000  0.178571\n",
        "3605  NLB015294_01  0.222222  0.185185\n",
        "1566  NLB070155_01  0.222222  0.185185\n",
        "3505  NLB070358_01  0.222222  0.151515\n",
        "1154  NLB113290_01  0.222222  0.151515\n",
        "1150  NLB146516_01  0.222222  0.151515\n",
        "285   NLB140482_01  0.222222  0.151515\n",
        "1998  NLB070770_01  0.222222  0.185185\n",
        "1924  NLB139342_01  0.222222  0.185185\n",
        "3579  NLB070754_01  0.222222  0.185185\n",
        "328   NLB074405_01  0.222222  0.238095\n",
        "1947  NLB123738_01  0.222222  0.166667\n",
        "926   NLB111622_01  0.235294  0.212766\n",
        "2264  NLB148240_01  0.250000  0.192308\n",
        "2918  NLB073318_01  0.250000  0.192308\n",
        "699   NLB109642_01  0.250000  0.192308\n",
        "1461  NLB112488_01  0.250000  0.217391\n",
        "3985  NLB112208_01  0.250000  0.192308\n",
        "1459  NLB074384_01  0.250000  0.217391\n",
        "2134  NLB073361_01  0.250000  0.250000\n",
        "980   NLB075546_01  0.250000  0.250000\n",
        "3490  NLB103620_01  0.250000  0.217391\n",
        "3028  NLB140807_01  0.250000  0.192308\n",
        "2100  NLB070176_01  0.250000  0.250000\n",
        "333   NLB070064_01  0.250000  0.250000\n",
        "86    NLB113289_01  0.250000  0.192308\n",
        "3686  NLB074171_01  0.250000  0.192308\n",
        "1643  NLB016606_01  0.250000  0.217391\n",
        "2618  NLB150170_01  0.250000  0.192308\n",
        "4028  NLB070638_01  0.266667  0.196078\n",
        "1763  NLB113257_01  0.285714  0.200000\n",
        "1443  NLB073704_02  0.285714  0.200000\n",
        "2526  NLB070385_01  0.285714  0.200000\n",
        "1660  NLB072795_01  0.285714  0.200000\n",
        "949   NLB074547_02  1.000000  1.000000\n",
        "3597  NLB141252_07  1.000000  1.000000\n",
        "2835  NLB140303_01  1.000000  1.000000\n",
        "3356  NLB074881_01  1.000000  1.000000\n",
        "3838  NLB131906_01  1.000000  1.000000\n",
        "582   NLB074575_01  1.000000  1.000000\n",
        "546   NLB139276_01  1.000000  1.000000\n",
        "2956  NLB146407_01  1.000000  1.000000\n",
        "2044  NLB143216_01  1.000000  1.000000\n",
        "1428  NLB139301_02  1.000000  1.000000\n",
        "3630  NLB074055_01  1.000000  1.000000\n",
        "1852  NLB144185_01  1.000000  1.000000\n",
        "3607  NLB073885_01  1.000000  1.000000\n",
        "1006  NLB139301_01  1.000000  1.000000\n",
        "2625  NLB073621_01  1.000000  1.000000\n",
        "1583  NLB070361_01  1.000000  1.000000\n",
        "2257  NLB073539_01  1.000000  1.000000\n",
        "2308  NLB074759_01  1.000000  1.000000\n",
        "4006  NLB127034_01  1.000000  1.000000\n",
        "2983  NLB140464_01  1.000000  1.000000\n",
        "575   NLB072708_01  1.000000  1.000000\n",
        "1263  NLB140468_01  1.000000  1.000000\n",
        "3284  NLB073664_01  1.000000  1.000000\n",
        "2061  NLB113247_01  1.000000  1.000000\n",
        "1236  NLB139028_01  1.000000  1.000000\n",
        "843   NLB076108_01  1.000000  1.000000\n",
        "2898  NLB124249_01  1.000000  1.000000\n",
        "2476  NLB070462_01  1.000000  1.000000\n",
        "1697  NLB074943_03  1.000000  1.000000\n",
        "2504  NLB071374_01  1.000000  1.000000\n",
        "1795  NLB112234_01  1.000000  1.000000\n",
        "2179  NLB070416_01  1.000000  1.000000\n",
        "2067  NLB143473_01  1.000000  1.000000\n",
        "3863  NLB074498_01  1.000000  1.000000\n",
        "3127  NLB072271_01  1.000000  1.000000\n",
        "1983  NLB072818_01  1.000000  1.000000\n",
        "2462  NLB070504_04  1.000000  1.000000\n",
        "3502  NLB074033_04  1.000000  1.000000\n",
        "68    NLB134040_01  1.000000  1.000000\n",
        "799   NLB071172_01  1.000000  1.000000\n",
        "120   NLB143244_01  1.000000  1.000000\n",
        "4000  NLB144548_01  1.000000  1.000000\n",
        "614   NLB071982_01  1.000000  1.000000\n",
        "3729  NLB074981_01  1.000000  1.000000\n",
        "1223  NLB070457_01  1.000000  1.000000\n",
        "2359  NLB112270_01  1.000000  1.000000\n",
        "2568  NLB147462_01  1.000000  1.000000\n",
        "2964  NLB123205_01  1.000000  1.000000\n",
        "986   NLB015056_01  1.000000  1.000000\n",
        "2331  NLB111467_01  1.000000  1.000000\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep the indices of the selected songs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "majority_scores_persong['F1'].plot(kind='kde')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x12df53c10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJtlBRERKSNkoKIiLRRUhARkTb/H05/2zlDvhxgAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x12df53590>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ixs_majority_selection = majority_sel.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we train a classifier using the weighted voting mechanism:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = RandomForestClassifier(n_estimators=50, min_samples_leaf=1, n_jobs=6)\n",
      "clf = CadenceClassifier(estimator, prediction_mode='weighted')\n",
      "proba_scores, proba_scores_persong = cross_validate(data, IDs, clf, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fold: 0, Class: 0, Precision: 0.966, Recall: 0.990, F-score 0.978\n",
        "Fold: 0, Class: 1, Precision: 0.904, Recall: 0.733, F-score 0.809\n",
        "Fold: 1, Class: 0, Precision: 0.964, Recall: 0.987, F-score 0.975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 1, Class: 1, Precision: 0.870, Recall: 0.709, F-score 0.782\n",
        "Fold: 2, Class: 0, Precision: 0.967, Recall: 0.989, F-score 0.978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 2, Class: 1, Precision: 0.901, Recall: 0.740, F-score 0.812\n",
        "Fold: 3, Class: 0, Precision: 0.964, Recall: 0.987, F-score 0.975"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 3, Class: 1, Precision: 0.875, Recall: 0.715, F-score 0.787\n",
        "Fold: 4, Class: 0, Precision: 0.961, Recall: 0.987, F-score 0.974"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 4, Class: 1, Precision: 0.882, Recall: 0.701, F-score 0.781\n",
        "Fold: 5, Class: 0, Precision: 0.968, Recall: 0.989, F-score 0.978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 5, Class: 1, Precision: 0.903, Recall: 0.750, F-score 0.820\n",
        "Fold: 6, Class: 0, Precision: 0.965, Recall: 0.990, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 6, Class: 1, Precision: 0.909, Recall: 0.724, F-score 0.806\n",
        "Fold: 7, Class: 0, Precision: 0.964, Recall: 0.987, F-score 0.976"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 7, Class: 1, Precision: 0.882, Recall: 0.720, F-score 0.793\n",
        "Fold: 8, Class: 0, Precision: 0.965, Recall: 0.989, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 8, Class: 1, Precision: 0.894, Recall: 0.719, F-score 0.797\n",
        "Fold: 9, Class: 0, Precision: 0.964, Recall: 0.990, F-score 0.977"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fold: 9, Class: 1, Precision: 0.904, Recall: 0.717, F-score 0.800\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Choose 30 best and worst for proba"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(0)\n",
      "proba_sel_bad = proba_scores_persong.sort('F1')[0:30]\n",
      "rows = np.random.choice(proba_scores_persong[proba_scores_persong['F1']==1.0].index.values, 30)\n",
      "proba_sel_good = proba_scores_persong.ix[rows]\n",
      "proba_sel = [proba_sel_bad, proba_sel_good]\n",
      "proba_sel = pd.concat(proba_sel)\n",
      "print proba_sel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                ID        F1        F2\n",
        "2964  NLB070708_01  0.000000  0.000000\n",
        "16    NLB074226_02  0.000000  0.000000\n",
        "4016  NLB072879_01  0.000000  0.000000\n",
        "4045  NLB140273_01  0.000000  0.000000\n",
        "2787  NLB075331_01  0.000000  0.000000\n",
        "1331  NLB112422_01  0.000000  0.000000\n",
        "394   NLB074877_01  0.000000  0.000000\n",
        "254   NLB140256_01  0.000000  0.000000\n",
        "376   NLB070465_01  0.000000  0.000000\n",
        "1325  NLB072396_04  0.000000  0.000000\n",
        "3662  NLB141172_01  0.142857  0.106383\n",
        "2177  NLB071196_01  0.166667  0.119048\n",
        "2553  NLB075167_01  0.181818  0.131579\n",
        "1454  NLB073858_01  0.181818  0.121951\n",
        "545   NLB070547_01  0.200000  0.227273\n",
        "1949  NLB015294_01  0.222222  0.185185\n",
        "1880  NLB070277_01  0.222222  0.185185\n",
        "900   NLB070855_01  0.222222  0.185185\n",
        "1439  NLB070358_01  0.222222  0.151515\n",
        "3629  NLB146516_01  0.222222  0.151515\n",
        "2764  NLB140482_01  0.222222  0.151515\n",
        "3236  NLB070770_01  0.222222  0.185185\n",
        "1004  NLB070854_01  0.222222  0.185185\n",
        "1927  NLB139342_01  0.222222  0.185185\n",
        "1745  NLB075887_01  0.222222  0.151515\n",
        "1966  NLB074405_01  0.222222  0.238095\n",
        "3066  NLB103620_01  0.250000  0.217391\n",
        "469   NLB073361_01  0.250000  0.250000\n",
        "3493  NLB112488_01  0.250000  0.217391\n",
        "1134  NLB076089_01  0.250000  0.172414\n",
        "2633  NLB040691_01  1.000000  1.000000\n",
        "2234  NLB123156_01  1.000000  1.000000\n",
        "3243  NLB134914_01  1.000000  1.000000\n",
        "2963  NLB074147_01  1.000000  1.000000\n",
        "4104  NLB071237_01  1.000000  1.000000\n",
        "1100  NLB071227_01  1.000000  1.000000\n",
        "2348  NLB075261_01  1.000000  1.000000\n",
        "2352  NLB071225_01  1.000000  1.000000\n",
        "1237  NLB070051_01  1.000000  1.000000\n",
        "2748  NLB111465_01  1.000000  1.000000\n",
        "2209  NLB122618_01  1.000000  1.000000\n",
        "327   NLB146399_01  1.000000  1.000000\n",
        "675   NLB074150_01  1.000000  1.000000\n",
        "3309  NLB074572_01  1.000000  1.000000\n",
        "2151  NLB074439_01  1.000000  1.000000\n",
        "3293  NLB070053_01  1.000000  1.000000\n",
        "269   NLB074541_03  1.000000  1.000000\n",
        "3009  NLB133664_01  1.000000  1.000000\n",
        "438   NLB070050_01  1.000000  1.000000\n",
        "3883  NLB140066_01  1.000000  1.000000\n",
        "2930  NLB143086_01  1.000000  1.000000\n",
        "1768  NLB072299_01  1.000000  1.000000\n",
        "3315  NLB142196_01  1.000000  1.000000\n",
        "373   NLB075587_02  1.000000  1.000000\n",
        "2930  NLB143086_01  1.000000  1.000000\n",
        "3092  NLB073286_04  1.000000  1.000000\n",
        "2558  NLB071666_01  1.000000  1.000000\n",
        "3566  NLB075902_06  1.000000  1.000000\n",
        "1673  NLB144336_01  1.000000  1.000000\n",
        "2687  NLB073046_01  1.000000  1.000000\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The scores of the individual fold can be inspected:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "majority_scores[['precision', 'recall']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>precision</th>\n",
        "      <th>recall</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.962742</td>\n",
        "      <td> 0.988337</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.890503</td>\n",
        "      <td> 0.712625</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.966514</td>\n",
        "      <td> 0.989194</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.899798</td>\n",
        "      <td> 0.738986</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.962530</td>\n",
        "      <td> 0.988699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.890552</td>\n",
        "      <td> 0.704945</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.962545</td>\n",
        "      <td> 0.989390</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.893963</td>\n",
        "      <td> 0.699097</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.965915</td>\n",
        "      <td> 0.986463</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.874803</td>\n",
        "      <td> 0.730989</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0.967102</td>\n",
        "      <td> 0.989413</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.899577</td>\n",
        "      <td> 0.738075</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0.965199</td>\n",
        "      <td> 0.988891</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0.894153</td>\n",
        "      <td> 0.724673</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0.962942</td>\n",
        "      <td> 0.987934</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0.884577</td>\n",
        "      <td> 0.708649</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 0.961411</td>\n",
        "      <td> 0.990536</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 0.907143</td>\n",
        "      <td> 0.699280</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 0.967826</td>\n",
        "      <td> 0.988200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 0.891271</td>\n",
        "      <td> 0.746473</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "    precision    recall\n",
        "0    0.962742  0.988337\n",
        "1    0.890503  0.712625\n",
        "2    0.966514  0.989194\n",
        "3    0.899798  0.738986\n",
        "4    0.962530  0.988699\n",
        "5    0.890552  0.704945\n",
        "6    0.962545  0.989390\n",
        "7    0.893963  0.699097\n",
        "8    0.965915  0.986463\n",
        "9    0.874803  0.730989\n",
        "10   0.967102  0.989413\n",
        "11   0.899577  0.738075\n",
        "12   0.965199  0.988891\n",
        "13   0.894153  0.724673\n",
        "14   0.962942  0.987934\n",
        "15   0.884577  0.708649\n",
        "16   0.961411  0.990536\n",
        "17   0.907143  0.699280\n",
        "18   0.967826  0.988200\n",
        "19   0.891271  0.746473"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The same for the probabilistic results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proba_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>fold</th>\n",
        "      <th>class</th>\n",
        "      <th>precision</th>\n",
        "      <th>recall</th>\n",
        "      <th>F</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.960588</td>\n",
        "      <td> 0.989327</td>\n",
        "      <td> 0.974746</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.894456</td>\n",
        "      <td> 0.690251</td>\n",
        "      <td> 0.779197</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.965678</td>\n",
        "      <td> 0.989360</td>\n",
        "      <td> 0.977376</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.899408</td>\n",
        "      <td> 0.730131</td>\n",
        "      <td> 0.805977</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.964221</td>\n",
        "      <td> 0.988882</td>\n",
        "      <td> 0.976396</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.894873</td>\n",
        "      <td> 0.720601</td>\n",
        "      <td> 0.798337</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.964815</td>\n",
        "      <td> 0.990714</td>\n",
        "      <td> 0.977593</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.911315</td>\n",
        "      <td> 0.725355</td>\n",
        "      <td> 0.807770</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.968081</td>\n",
        "      <td> 0.988085</td>\n",
        "      <td> 0.977981</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.886735</td>\n",
        "      <td> 0.741151</td>\n",
        "      <td> 0.807433</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.965296</td>\n",
        "      <td> 0.989840</td>\n",
        "      <td> 0.977414</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.905322</td>\n",
        "      <td> 0.731899</td>\n",
        "      <td> 0.809426</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.962444</td>\n",
        "      <td> 0.989149</td>\n",
        "      <td> 0.975614</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 6</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.893255</td>\n",
        "      <td> 0.701710</td>\n",
        "      <td> 0.785981</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 7</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.965663</td>\n",
        "      <td> 0.987984</td>\n",
        "      <td> 0.976696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 7</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.887657</td>\n",
        "      <td> 0.729909</td>\n",
        "      <td> 0.801091</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 8</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.966549</td>\n",
        "      <td> 0.987851</td>\n",
        "      <td> 0.977084</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 8</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.888450</td>\n",
        "      <td> 0.738916</td>\n",
        "      <td> 0.806813</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 9</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.963734</td>\n",
        "      <td> 0.987921</td>\n",
        "      <td> 0.975678</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 9</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.883943</td>\n",
        "      <td> 0.712212</td>\n",
        "      <td> 0.788839</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "    fold  class  precision    recall         F\n",
        "0      0      0   0.960588  0.989327  0.974746\n",
        "1      0      1   0.894456  0.690251  0.779197\n",
        "2      1      0   0.965678  0.989360  0.977376\n",
        "3      1      1   0.899408  0.730131  0.805977\n",
        "4      2      0   0.964221  0.988882  0.976396\n",
        "5      2      1   0.894873  0.720601  0.798337\n",
        "6      3      0   0.964815  0.990714  0.977593\n",
        "7      3      1   0.911315  0.725355  0.807770\n",
        "8      4      0   0.968081  0.988085  0.977981\n",
        "9      4      1   0.886735  0.741151  0.807433\n",
        "10     5      0   0.965296  0.989840  0.977414\n",
        "11     5      1   0.905322  0.731899  0.809426\n",
        "12     6      0   0.962444  0.989149  0.975614\n",
        "13     6      1   0.893255  0.701710  0.785981\n",
        "14     7      0   0.965663  0.987984  0.976696\n",
        "15     7      1   0.887657  0.729909  0.801091\n",
        "16     8      0   0.966549  0.987851  0.977084\n",
        "17     8      1   0.888450  0.738916  0.806813\n",
        "18     9      0   0.963734  0.987921  0.975678\n",
        "19     9      1   0.883943  0.712212  0.788839"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As can be seen from the following two tables, on average the two voting system perform equally well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "majority_scores.groupby(['class', 'fold'])[['precision', 'recall', 'F']].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th>precision</th>\n",
        "      <th>recall</th>\n",
        "      <th>F</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>class</th>\n",
        "      <th>fold</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th rowspan=\"10\" valign=\"top\">0</th>\n",
        "      <th>0</th>\n",
        "      <td> 0.962742</td>\n",
        "      <td> 0.988337</td>\n",
        "      <td> 0.975372</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.966514</td>\n",
        "      <td> 0.989194</td>\n",
        "      <td> 0.977723</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.962530</td>\n",
        "      <td> 0.988699</td>\n",
        "      <td> 0.975439</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.962545</td>\n",
        "      <td> 0.989390</td>\n",
        "      <td> 0.975783</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.965915</td>\n",
        "      <td> 0.986463</td>\n",
        "      <td> 0.976081</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0.967102</td>\n",
        "      <td> 0.989413</td>\n",
        "      <td> 0.978130</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 0.965199</td>\n",
        "      <td> 0.988891</td>\n",
        "      <td> 0.976901</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0.962942</td>\n",
        "      <td> 0.987934</td>\n",
        "      <td> 0.975278</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0.961411</td>\n",
        "      <td> 0.990536</td>\n",
        "      <td> 0.975756</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0.967826</td>\n",
        "      <td> 0.988200</td>\n",
        "      <td> 0.977907</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
        "      <th>0</th>\n",
        "      <td> 0.890503</td>\n",
        "      <td> 0.712625</td>\n",
        "      <td> 0.791696</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.899798</td>\n",
        "      <td> 0.738986</td>\n",
        "      <td> 0.811502</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.890552</td>\n",
        "      <td> 0.704945</td>\n",
        "      <td> 0.786953</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.893963</td>\n",
        "      <td> 0.699097</td>\n",
        "      <td> 0.784612</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.874803</td>\n",
        "      <td> 0.730989</td>\n",
        "      <td> 0.796456</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0.899577</td>\n",
        "      <td> 0.738075</td>\n",
        "      <td> 0.810862</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 0.894153</td>\n",
        "      <td> 0.724673</td>\n",
        "      <td> 0.800542</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0.884577</td>\n",
        "      <td> 0.708649</td>\n",
        "      <td> 0.786900</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0.907143</td>\n",
        "      <td> 0.699280</td>\n",
        "      <td> 0.789763</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0.891271</td>\n",
        "      <td> 0.746473</td>\n",
        "      <td> 0.812471</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "            precision    recall         F\n",
        "class fold                               \n",
        "0     0      0.962742  0.988337  0.975372\n",
        "      1      0.966514  0.989194  0.977723\n",
        "      2      0.962530  0.988699  0.975439\n",
        "      3      0.962545  0.989390  0.975783\n",
        "      4      0.965915  0.986463  0.976081\n",
        "      5      0.967102  0.989413  0.978130\n",
        "      6      0.965199  0.988891  0.976901\n",
        "      7      0.962942  0.987934  0.975278\n",
        "      8      0.961411  0.990536  0.975756\n",
        "      9      0.967826  0.988200  0.977907\n",
        "1     0      0.890503  0.712625  0.791696\n",
        "      1      0.899798  0.738986  0.811502\n",
        "      2      0.890552  0.704945  0.786953\n",
        "      3      0.893963  0.699097  0.784612\n",
        "      4      0.874803  0.730989  0.796456\n",
        "      5      0.899577  0.738075  0.810862\n",
        "      6      0.894153  0.724673  0.800542\n",
        "      7      0.884577  0.708649  0.786900\n",
        "      8      0.907143  0.699280  0.789763\n",
        "      9      0.891271  0.746473  0.812471"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proba_scores.groupby('class')[['precision', 'recall', 'F']].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>precision</th>\n",
        "      <th>recall</th>\n",
        "      <th>F</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>class</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.964707</td>\n",
        "      <td> 0.988911</td>\n",
        "      <td> 0.976658</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.894542</td>\n",
        "      <td> 0.722214</td>\n",
        "      <td> 0.799086</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "       precision    recall         F\n",
        "class                               \n",
        "0       0.964707  0.988911  0.976658\n",
        "1       0.894542  0.722214  0.799086"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print majority_scores_persong.ix[3932]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ID    NLB112488_01\n",
        "F1       0.2222222\n",
        "F2       0.2083333\n",
        "Name: 3932, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "IDs[3932]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "'NLB144340_01'"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}